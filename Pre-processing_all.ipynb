{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a36aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import signal\n",
    "from numpy import linalg as LA\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788e4111",
   "metadata": {},
   "source": [
    "\n",
    "### 実験設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01abd936",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTICIPANTS = ['oba', 'ono', 'pon', 'kuno', 'john', 'konan', \n",
    "                'obara', 'fukuzawa', 'kiuchi', 'yanaze', 'adachi', 'iwasaki']\n",
    "MASSES = [60.9, 63.8, 68.7, 65.9, 77, 74, 63.8, 64.5, 73.2, 53.5, 70.7, 47.9]\n",
    "CONDITIONS = ['h', 'm', 'l']\n",
    "\n",
    "# サンプリング周波数\n",
    "DEVICE_FREQ = 100\n",
    "MOCAP_FREQ = 250\n",
    "FORCE_FREQ = 1000\n",
    "\n",
    "# フィルタ設定\n",
    "CUTOFF_FREQ = 6\n",
    "FILTER_ORDER = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f10293",
   "metadata": {},
   "source": [
    "### 1. データ読み込み関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "207a794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_data(participant, condition, mass):\n",
    "    \"\"\"\n",
    "    指定された実験協力者・条件のデータを読み込む\n",
    "    \n",
    "    Parameters:\n",
    "        participant: 実験協力者名\n",
    "        condition: 実験条件 ('h', 'm', 'l')\n",
    "        mass: 体重 [kg]\n",
    "    \n",
    "    Returns:\n",
    "        dict: 各種データフレームと体重情報\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {participant} - Condition: {condition.upper()} (Mass: {mass} kg)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # ファイルパス生成\n",
    "    file_path_left = f\"WearableDevices/{participant}_{condition}_left_foot_data.csv\"\n",
    "    file_path_right = f\"WearableDevices/{participant}_{condition}_right_foot_data.csv\"\n",
    "    file_path_mocap = f\"MotionCaptures/{participant}_{condition}_mocap.csv\"\n",
    "    file_path_force = f\"3DGroundForces/{participant}_{condition}_force.csv\"\n",
    "    \n",
    "    # データ読み込み\n",
    "    df_left = pd.read_csv(file_path_left, header=0)\n",
    "    df_right = pd.read_csv(file_path_right, header=0)\n",
    "    df_mocap = pd.read_csv(file_path_mocap, header=[2, 5, 6])\n",
    "    df_force = pd.read_csv(file_path_force, header=10, encoding='shift_jis')\n",
    "    \n",
    "    return {\n",
    "        'left': df_left,\n",
    "        'right': df_right,\n",
    "        'mocap': df_mocap,\n",
    "        'force': df_force,\n",
    "        'mass': mass,\n",
    "        'participant': participant,\n",
    "        'condition': condition\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15446c8e",
   "metadata": {},
   "source": [
    "### 2. モーションキャプチャデータの列名整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e581f19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_mocap_columns(df_mocap):\n",
    "    \"\"\"モーションキャプチャデータの列名を整理\"\"\"\n",
    "    new_columns = []\n",
    "    \n",
    "    for col in df_mocap.columns:\n",
    "        if col[2] == 'Frame':\n",
    "            new_columns.append('Frame')\n",
    "        elif 'Time' in col[2]:\n",
    "            new_columns.append('Time (Seconds)')\n",
    "        else:\n",
    "            body_num = col[0].replace('Rigid Body', '').strip()\n",
    "            name = f\"{body_num}_{col[1]}_{col[2]}\"\n",
    "            new_columns.append(name)\n",
    "    \n",
    "    df_mocap.columns = new_columns\n",
    "    return df_mocap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b407e99",
   "metadata": {},
   "source": [
    "### 3. 床反力データの列名整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "737e9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_force_columns(df_force):\n",
    "    \"\"\"床反力データの列名を英語に変換\"\"\"\n",
    "    columns_mapping = {\n",
    "        'Unnamed: 0': 'Time (Seconds)',\n",
    "        '右-Fx': 'Right_Fx', '右-Fy': 'Right_Fy', '右-Fz': 'Right_Fz',\n",
    "        '右-Mx': 'Right_Mx', '右-My': 'Right_My', '右-Mz': 'Right_Mz',\n",
    "        '右-COPx': 'Right_COPx', '右-COPy': 'Right_COPy',\n",
    "        '左-Fx': 'Left_Fx', '左-Fy': 'Left_Fy', '左-Fz': 'Left_Fz',\n",
    "        '左-Mx': 'Left_Mx', '左-My': 'Left_My', '左-Mz': 'Left_Mz',\n",
    "        '左-COPx': 'Left_COPx', '左-COPy': 'Left_COPy',\n",
    "    }\n",
    "    return df_force.rename(columns=columns_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cba2bb",
   "metadata": {},
   "source": [
    " ### 4. リサンプリング\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3526e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resampling(df_input, sampling_interval=10):\n",
    "    \"\"\"\n",
    "    データのリサンプリング，軸反転，単位変換を実行\n",
    "    \n",
    "    Parameters:\n",
    "        df_input: 入力データフレーム\n",
    "        sampling_interval: サンプリング間隔 [ms]\n",
    "    \"\"\"\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # 欠損値補完\n",
    "    exclude_cols = ['Marker']\n",
    "    target_cols = df.columns.difference(exclude_cols)\n",
    "    df[target_cols] = df[target_cols].interpolate(method='linear', axis=0)\n",
    "    \n",
    "    # 新しい時間軸作成\n",
    "    time_min = 0\n",
    "    time_max = df['ElapsedTime'].max()\n",
    "    new_time = np.arange(time_min, time_max, sampling_interval)\n",
    "    df_resampled = pd.DataFrame({'ElapsedTime': new_time})\n",
    "    \n",
    "    # マーカー列の処理\n",
    "    if exclude_cols:\n",
    "        df_markers = df[['ElapsedTime'] + exclude_cols].dropna(subset=exclude_cols, how='all').copy()\n",
    "        df_markers['ElapsedTime_rounded'] = (df_markers['ElapsedTime'] / sampling_interval).round() * sampling_interval\n",
    "        df_markers = df_markers.drop_duplicates(subset=['ElapsedTime_rounded'])\n",
    "        \n",
    "        df_resampled['MergeKey'] = df_resampled['ElapsedTime'].round().astype(int)\n",
    "        df_markers['MergeKey'] = df_markers['ElapsedTime_rounded'].round().astype(int)\n",
    "        \n",
    "        df_resampled = pd.merge(df_resampled, df_markers[['MergeKey'] + exclude_cols],\n",
    "                                on='MergeKey', how='left')\n",
    "        df_resampled = df_resampled.drop(columns=['MergeKey'])\n",
    "    \n",
    "    # 連続値データの補間\n",
    "    columns_to_exclude = ['ElapsedTime'] + exclude_cols\n",
    "    for column in df.columns:\n",
    "        if column in columns_to_exclude:\n",
    "            continue\n",
    "        interpolator = interp1d(df['ElapsedTime'], df[column], \n",
    "                                kind='linear', fill_value='extrapolate')\n",
    "        df_resampled[column] = interpolator(new_time)\n",
    "    \n",
    "    # 単位変換\n",
    "    df_resampled['ElapsedTime'] = df_resampled['ElapsedTime'] / 1000\n",
    "    df_resampled = df_resampled.rename(columns={'ElapsedTime': 'Time (Seconds)'})\n",
    "    \n",
    "    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40ae607",
   "metadata": {},
   "source": [
    "### 5. ローパスフィルタ適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d291a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lowpass_filter(data, cutoff, fs, order=4):\n",
    "    \"\"\"Butterworthローパスフィルタ\"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return signal.filtfilt(b, a, data, axis=0)\n",
    "\n",
    "def process_smoothing_dataframe(df_input, fs=DEVICE_FREQ, cutoff=CUTOFF_FREQ, order=FILTER_ORDER):\n",
    "    \"\"\"データフレーム全体にフィルタを適用\"\"\"\n",
    "    df_smooth = df_input.copy()\n",
    "    \n",
    "    exclude_keywords = ['Time (Seconds)', 'Marker']\n",
    "    filter_target_cols = [col for col in df_smooth.columns \n",
    "                          if col not in exclude_keywords and 'Marker' not in col]\n",
    "    \n",
    "    # 欠損値補完\n",
    "    df_smooth[filter_target_cols] = df_smooth[filter_target_cols].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "    df_smooth[filter_target_cols] = df_smooth[filter_target_cols].fillna(0)\n",
    "    \n",
    "    # フィルタ適用\n",
    "    df_smooth[filter_target_cols] = apply_lowpass_filter(\n",
    "        df_smooth[filter_target_cols].values, cutoff=cutoff, fs=fs, order=order)\n",
    "    \n",
    "    # 圧力データのクリッピング（負値を0に）\n",
    "    pressure_cols = [col for col in filter_target_cols if 'kPa' in col]\n",
    "    if pressure_cols:\n",
    "        df_pressure = df_smooth[pressure_cols]\n",
    "        df_smooth[pressure_cols] = df_pressure.mask(df_pressure < 0, 0)\n",
    "    \n",
    "    return df_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b6c7a3",
   "metadata": {},
   "source": [
    "### 6. 関節角度計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07a8c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マーカーインデックス定義\n",
    "R_ILIUM_INDEX = 1\n",
    "R_GREATER_TROCHANTER_INDEX = 2\n",
    "R_KNEE_INDEX = 3\n",
    "R_MALLEOLUS_INDEX = 4\n",
    "R_TOE_INDEX = 5\n",
    "L_ILIUM_INDEX = 6\n",
    "L_GREATER_TROCHANTER_INDEX = 7\n",
    "L_KNEE_INDEX = 8\n",
    "L_MALLEOLUS_INDEX = 9\n",
    "L_TOE_INDEX = 10\n",
    "JOINT_NO = 6\n",
    "\n",
    "class CalculateAngle:\n",
    "    \"\"\"関節角度計算クラス\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _vec(A, B, C):\n",
    "        return np.stack((A - B, C - B), axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _angle2d(a, b):\n",
    "        inner = np.dot(a, b)\n",
    "        norm_a = LA.norm(a)\n",
    "        norm_b = LA.norm(b)\n",
    "        \n",
    "        if norm_a < 1e-4 or norm_b < 1e-4:\n",
    "            return 0.0\n",
    "        \n",
    "        norm = norm_a * norm_b\n",
    "        return np.degrees(np.arccos(np.clip(inner / norm, -1, 1)))\n",
    "    \n",
    "    def _angle3d(self, v):\n",
    "        deg = np.zeros(3)\n",
    "        pairs = [\n",
    "            (slice(None, 2), 0),\n",
    "            (slice(1, None), 1),\n",
    "            ((2, 0), 2)\n",
    "        ]\n",
    "        \n",
    "        for i, (sl, _) in enumerate(pairs):\n",
    "            a = v[0][sl] if isinstance(sl, slice) else v[0][list(sl)]\n",
    "            b = v[1][sl] if isinstance(sl, slice) else v[1][list(sl)]\n",
    "            S = 0.5 * (b[0] * a[1] - b[1] * a[0])\n",
    "            ang = self._angle2d(a, b)\n",
    "            deg[i] = 360 - ang if S < 0 else ang\n",
    "        return deg\n",
    "    \n",
    "    def angles(self, pos):\n",
    "        pos = pos[:, [0, 2, 1]].copy()\n",
    "        pos[:, 0] *= -1\n",
    "        out = np.zeros((JOINT_NO, 3))\n",
    "        idxs = [\n",
    "            (R_ILIUM_INDEX - 1, R_GREATER_TROCHANTER_INDEX - 1, R_KNEE_INDEX - 1),\n",
    "            (L_ILIUM_INDEX - 1, L_GREATER_TROCHANTER_INDEX - 1, L_KNEE_INDEX - 1),\n",
    "            (R_GREATER_TROCHANTER_INDEX - 1, R_KNEE_INDEX - 1, R_MALLEOLUS_INDEX - 1),\n",
    "            (L_GREATER_TROCHANTER_INDEX - 1, L_KNEE_INDEX - 1, L_MALLEOLUS_INDEX - 1),\n",
    "            (R_KNEE_INDEX - 1, R_MALLEOLUS_INDEX - 1, R_TOE_INDEX - 1),\n",
    "            (L_KNEE_INDEX - 1, L_MALLEOLUS_INDEX - 1, L_TOE_INDEX - 1),\n",
    "        ]\n",
    "        for i, (a, b, c) in enumerate(idxs):\n",
    "            out[i] = self._angle3d(self._vec(pos[a], pos[b], pos[c]))\n",
    "        return out\n",
    "\n",
    "def calculate_angles_from_positions(df, target_cols):\n",
    "    \"\"\"データフレームから関節角度を計算\"\"\"\n",
    "    calculator = CalculateAngle()\n",
    "    positions_flat = df[target_cols].values\n",
    "    n_frames = positions_flat.shape[0]\n",
    "    \n",
    "    if n_frames == 0:\n",
    "        return np.empty((0, 18))\n",
    "    \n",
    "    positions_3d = positions_flat.reshape(n_frames, 10, 3)\n",
    "    all_angles = []\n",
    "    \n",
    "    for frame_idx in range(n_frames):\n",
    "        current_pos = positions_3d[frame_idx]\n",
    "        angles = calculator.angles(current_pos)\n",
    "        all_angles.append(angles.flatten())\n",
    "    \n",
    "    return np.array(all_angles)\n",
    "\n",
    "def process_mocap_data_target_calibration(df_target, df_ref):\n",
    "    \"\"\"\n",
    "    モーションキャプチャデータから関節角度を計算し，キャリブレーション補正を実施\n",
    "    \n",
    "    Parameters:\n",
    "        df_target: 解析対象データ\n",
    "        df_ref: タイミング特定用データ\n",
    "    \"\"\"\n",
    "    target_cols = []\n",
    "    for i in range(1, 11):\n",
    "        prefix = f\"{i:03}\"\n",
    "        target_cols.extend([f\"{prefix}_Position_X\", f\"{prefix}_Position_Y\", f\"{prefix}_Position_Z\"])\n",
    "    \n",
    "    # キャリブレーション時間の特定\n",
    "    trigger_rows = df_ref[df_ref['Marker'] == 2]\n",
    "    if trigger_rows.empty:\n",
    "        raise ValueError(\"Marker == 2 が見つかりません\")\n",
    "    \n",
    "    trigger_time = trigger_rows.iloc[0]['Time (Seconds)']\n",
    "    start_time = trigger_time - 20.0\n",
    "    end_time = trigger_time - 15.0\n",
    "    \n",
    "    # 基準姿勢データの抽出\n",
    "    mask = (df_target['Time (Seconds)'] >= start_time) & (df_target['Time (Seconds)'] <= end_time)\n",
    "    df_base_window = df_target.loc[mask].copy()\n",
    "    \n",
    "    if len(df_base_window) == 0:\n",
    "        raise ValueError(\"基準区間にデータが存在しません\")\n",
    "    \n",
    "    # 基準姿勢の計算\n",
    "    ref_angles = calculate_angles_from_positions(df_base_window, target_cols)\n",
    "    base_pose_mean = np.mean(ref_angles, axis=0)\n",
    "    \n",
    "    # 全データの角度計算と補正\n",
    "    target_angles = calculate_angles_from_positions(df_target, target_cols)\n",
    "    relative_angles = target_angles - base_pose_mean\n",
    "    \n",
    "    # DataFrame作成\n",
    "    joint_names = [\"Right_Hip\", \"Left_Hip\", \"Right_Knee\", \"Left_Knee\", \"Right_Ankle\", \"Left_Ankle\"]\n",
    "    plane_names = [\"XY\", \"YZ\", \"ZX\"]\n",
    "    columns = []\n",
    "    for joint in joint_names:\n",
    "        for plane in plane_names:\n",
    "            columns.append(f\"{joint}_{plane}\")\n",
    "    \n",
    "    df_result = pd.DataFrame(relative_angles, columns=columns)\n",
    "    \n",
    "    if 'Time (Seconds)' in df_target.columns:\n",
    "        df_result.insert(0, 'Time (Seconds)', df_target['Time (Seconds)'].values)\n",
    "    \n",
    "    return df_result, base_pose_mean, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad766ed",
   "metadata": {},
   "source": [
    "### 7. 床反力の正規化（体重比）[%BW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5f6a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_force_by_bodyweight(df_force, mass):\n",
    "    \"\"\"床反力を体重で正規化\"\"\"\n",
    "    columns = ['Time (Seconds)', 'Right_Fx', 'Right_Fy', 'Right_Fz', \n",
    "               'Left_Fx', 'Left_Fy', 'Left_Fz']\n",
    "    force_columns = ['Right_Fx', 'Right_Fy', 'Right_Fz', 'Left_Fx', 'Left_Fy', 'Left_Fz']\n",
    "    \n",
    "    body_weight = mass * 9.81\n",
    "    df_normalized = df_force[columns].copy()\n",
    "    df_normalized[force_columns] /= body_weight\n",
    "    \n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec91ff",
   "metadata": {},
   "source": [
    "### 8. 圧力データ (Pressure) -> Min-Max (0~1)\n",
    "###    IMUデータ (その他)    -> Z-score (平均0, 分散1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1dfa4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hybrid_normalization(df_input, duration=300):\n",
    "    \"\"\"\n",
    "    マーカー2から指定時間のデータを使用し、\n",
    "    - 圧力データ (Pressure) -> Min-Max (0~1)\n",
    "    - IMUデータ (その他)    -> Z-score (平均0, 分散1)\n",
    "    に正規化する\n",
    "    \"\"\"\n",
    "    df_norm = df_input.copy()\n",
    "    df_norm.columns = df_norm.columns.str.replace('kPa', 'Pressure')\n",
    "    \n",
    "    exclude_keywords = ['Time (Seconds)', 'Marker']\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. 列の分類 (圧力か、それ以外(IMU)か)\n",
    "    # ---------------------------------------------------------\n",
    "    # 'Pressure' という文字が含まれる列を抽出\n",
    "    pressure_cols = [col for col in df_norm.columns if 'Pressure' in col]\n",
    "    \n",
    "    # それ以外の数値データ列をIMUとして扱う\n",
    "    imu_cols = [col for col in df_norm.columns \n",
    "                if col not in exclude_keywords \n",
    "                and 'Marker' not in col \n",
    "                and col not in pressure_cols]\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 2. 基準となる期間(300秒)のデータ抽出\n",
    "    # ---------------------------------------------------------\n",
    "    start_time = 0\n",
    "    marker_cols = [col for col in df_norm.columns if 'Marker' in col]\n",
    "    \n",
    "    if marker_cols:\n",
    "        marker_2_rows = df_norm[(df_norm[marker_cols] == 2).any(axis=1)]\n",
    "        if not marker_2_rows.empty:\n",
    "            start_time = marker_2_rows.iloc[0]['Time (Seconds)']\n",
    "    \n",
    "    end_time = start_time + duration\n",
    "    mask = (df_norm['Time (Seconds)'] >= start_time) & (df_norm['Time (Seconds)'] <= end_time)\n",
    "    df_stats_base = df_norm.loc[mask]\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 3. IMUデータの正規化 -> Z-score\n",
    "    # ---------------------------------------------------------\n",
    "    if imu_cols:\n",
    "        means = df_stats_base[imu_cols].mean()\n",
    "        stds = df_stats_base[imu_cols].std()\n",
    "        stds = stds.replace(0, 1) # 0除算回避\n",
    "        \n",
    "        # 全データに対して適用\n",
    "        df_norm[imu_cols] = (df_norm[imu_cols] - means) / stds\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. 足底圧力データの正規化 -> Min-Max (0~1)\n",
    "    # ---------------------------------------------------------\n",
    "    if pressure_cols:\n",
    "        mins = df_stats_base[pressure_cols].min()\n",
    "        maxs = df_stats_base[pressure_cols].max()\n",
    "        ranges = maxs - mins\n",
    "        ranges = ranges.replace(0, 1) # 0除算回避\n",
    "        \n",
    "        # 全データに対して適用\n",
    "        df_norm[pressure_cols] = (df_norm[pressure_cols] - mins) / ranges\n",
    "\n",
    "    # 戻り値: データフレームと、後で確認・逆変換できるように統計量も返す\n",
    "    stats_info = {\n",
    "        \"imu_mean\": means if imu_cols else None,\n",
    "        \"imu_std\": stds if imu_cols else None,\n",
    "        \"press_min\": mins if pressure_cols else None,\n",
    "        \"press_max\": maxs if pressure_cols else None\n",
    "    }\n",
    "    \n",
    "    return df_norm, stats_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6e9b8",
   "metadata": {},
   "source": [
    "### 9. データ同期と結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb61ba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fine_offset_pressure(df_target, df_ref, col_target_pressure_list, \n",
    "                                   col_ref_name, t_start, duration=300, fs=100):\n",
    "    \"\"\"足底圧と床反力の相互相関によるタイミング補正\"\"\"\n",
    "    t_end = t_start + duration\n",
    "    \n",
    "    mask_tgt = (df_target['Time (Seconds)'] >= t_start) & (df_target['Time (Seconds)'] <= t_end)\n",
    "    df_t = df_target.loc[mask_tgt].copy()\n",
    "    \n",
    "    mask_ref = (df_ref['Time (Seconds)'] >= t_start) & (df_ref['Time (Seconds)'] <= t_end)\n",
    "    df_r = df_ref.loc[mask_ref].copy()\n",
    "    \n",
    "    if len(df_t) < fs or len(df_r) < fs:\n",
    "        return 0.0\n",
    "    \n",
    "    t_min = max(df_t['Time (Seconds)'].min(), df_r['Time (Seconds)'].min())\n",
    "    t_max = min(df_t['Time (Seconds)'].max(), df_r['Time (Seconds)'].max())\n",
    "    \n",
    "    if t_min >= t_max:\n",
    "        return 0.0\n",
    "    \n",
    "    common_t = np.arange(t_min, t_max, 1.0/fs)\n",
    "    \n",
    "    pressure_sum = df_t[col_target_pressure_list].sum(axis=1)\n",
    "    f_tgt = interp1d(df_t['Time (Seconds)'], pressure_sum, \n",
    "                     kind='linear', fill_value=0, bounds_error=False)\n",
    "    sig_tgt = f_tgt(common_t)\n",
    "    \n",
    "    f_ref = interp1d(df_r['Time (Seconds)'], df_r[col_ref_name], \n",
    "                     kind='linear', fill_value=0, bounds_error=False)\n",
    "    sig_ref = f_ref(common_t)\n",
    "    \n",
    "    sig_tgt_norm = (sig_tgt - np.mean(sig_tgt)) / (np.std(sig_tgt) + 1e-6)\n",
    "    sig_ref_norm = (sig_ref - np.mean(sig_ref)) / (np.std(sig_ref) + 1e-6)\n",
    "    \n",
    "    correlation = signal.correlate(sig_ref_norm, sig_tgt_norm, mode='full')\n",
    "    lags = signal.correlation_lags(len(sig_ref_norm), len(sig_tgt_norm), mode='full')\n",
    "    best_lag = lags[np.argmax(correlation)]\n",
    "    \n",
    "    return best_lag / fs\n",
    "\n",
    "def synchronize_merge_and_extract(df_left, df_right, df_angles, df_force, target_freq=100):\n",
    "    \"\"\"\n",
    "    全データの同期・結合・抽出\n",
    "    Marker 1で粗調整 → 足底圧で微調整 → 結合 → Marker 2から300秒抽出\n",
    "    \"\"\"\n",
    "    # Marker 1による粗調整\n",
    "    trigger_marker = 1\n",
    "    marker_rows_l = df_left[df_left['Marker'] == trigger_marker]\n",
    "    t_marker_left_1 = 0.0\n",
    "    if not marker_rows_l.empty:\n",
    "        t_marker_left_1 = marker_rows_l.iloc[0]['Time (Seconds)']\n",
    "    \n",
    "    df_right_rough = df_right.copy()\n",
    "    marker_rows_r = df_right[df_right['Marker'] == trigger_marker]\n",
    "    if not marker_rows_r.empty:\n",
    "        t_marker_r_1 = marker_rows_r.iloc[0]['Time (Seconds)']\n",
    "        offset_r_rough = t_marker_left_1 - t_marker_r_1\n",
    "        df_right_rough['Time (Seconds)'] += offset_r_rough\n",
    "    \n",
    "    df_force_rough = df_force.copy()\n",
    "    df_force_rough['Time (Seconds)'] += t_marker_left_1\n",
    "    \n",
    "    # Marker 2 + 300sによる微調整\n",
    "    fine_tune_marker = 2\n",
    "    duration = 300\n",
    "    cols_Pressure_left = [f'Left_Pressure_{i}' for i in range(1, 9)]\n",
    "    cols_Pressure_right = [f'Right_Pressure_{i}' for i in range(1, 9)]\n",
    "    \n",
    "    marker_rows_l_2 = df_left[df_left['Marker'] == fine_tune_marker]\n",
    "    \n",
    "    df_left_final = df_left.copy()\n",
    "    df_right_final = df_right_rough.copy()\n",
    "    df_angles_final = df_angles.copy()\n",
    "    \n",
    "    if not marker_rows_l_2.empty:\n",
    "        t_start_fine = marker_rows_l_2.iloc[0]['Time (Seconds)']\n",
    "        \n",
    "        offset_l_fine = calculate_fine_offset_pressure(\n",
    "            df_target=df_left, df_ref=df_force_rough, \n",
    "            col_target_pressure_list=cols_Pressure_left,\n",
    "            col_ref_name='Left_Fz', t_start=t_start_fine, \n",
    "            duration=duration, fs=target_freq\n",
    "        )\n",
    "        \n",
    "        offset_r_fine = calculate_fine_offset_pressure(\n",
    "            df_target=df_right_rough, df_ref=df_force_rough, \n",
    "            col_target_pressure_list=cols_Pressure_right,\n",
    "            col_ref_name='Right_Fz', t_start=t_start_fine, \n",
    "            duration=duration, fs=target_freq\n",
    "        )\n",
    "        \n",
    "        df_left_final['Time (Seconds)'] += offset_l_fine\n",
    "        df_angles_final['Time (Seconds)'] += offset_l_fine\n",
    "        df_right_final['Time (Seconds)'] += offset_r_fine\n",
    "    \n",
    "    df_force_final = df_force_rough\n",
    "    \n",
    "    # 統合用時間軸の作成\n",
    "    t_start = max(df_left_final['Time (Seconds)'].min(), \n",
    "                  df_right_final['Time (Seconds)'].min(),\n",
    "                  df_angles_final['Time (Seconds)'].min(), \n",
    "                  df_force_final['Time (Seconds)'].min())\n",
    "    t_end = min(df_left_final['Time (Seconds)'].max(), \n",
    "                df_right_final['Time (Seconds)'].max(),\n",
    "                df_angles_final['Time (Seconds)'].max(), \n",
    "                df_force_final['Time (Seconds)'].max())\n",
    "    \n",
    "    common_time = np.arange(t_start, t_end, 1.0/target_freq)\n",
    "    df_merged = pd.DataFrame({'Time (Seconds)': common_time})\n",
    "    \n",
    "    # リサンプリングと結合\n",
    "    data_sources = {'L_Dev': df_left_final, 'R_Dev': df_right_final, \n",
    "                    'Mocap': df_angles_final, 'Force': df_force_final}\n",
    "    \n",
    "    for prefix, df_src in data_sources.items():\n",
    "        time_col = 'Time (Seconds)' if 'Time (Seconds)' in df_src.columns else 'Time'\n",
    "        numeric_cols = df_src.select_dtypes(include=[np.number]).columns\n",
    "        cols_to_interp = [c for c in numeric_cols if c != time_col and 'Marker' not in c]\n",
    "        \n",
    "        if not cols_to_interp:\n",
    "            continue\n",
    "        \n",
    "        f = interp1d(df_src[time_col], df_src[cols_to_interp], axis=0, \n",
    "                     kind='linear', fill_value=\"extrapolate\")\n",
    "        interp_data = f(common_time)\n",
    "        df_temp = pd.DataFrame(interp_data, columns=cols_to_interp)\n",
    "        df_merged = pd.concat([df_merged, df_temp], axis=1)\n",
    "    \n",
    "    df_merged = df_merged.loc[:, ~df_merged.columns.duplicated()]\n",
    "    \n",
    "    # Marker 2から300秒間の抽出\n",
    "    marker_rows_sync = df_left_final[df_left_final['Marker'] == 2]\n",
    "    \n",
    "    if not marker_rows_sync.empty:\n",
    "        synced_start_time = marker_rows_sync.iloc[0]['Time (Seconds)']\n",
    "        synced_end_time = synced_start_time + 300.0\n",
    "        \n",
    "        df_analysis = df_merged[\n",
    "            (df_merged['Time (Seconds)'] >= synced_start_time) & \n",
    "            (df_merged['Time (Seconds)'] <= synced_end_time)\n",
    "        ].copy()\n",
    "        \n",
    "        df_analysis['Time (Seconds)'] = df_analysis['Time (Seconds)'] - synced_start_time\n",
    "        df_analysis = df_analysis.reset_index(drop=True)\n",
    "        \n",
    "        return df_analysis\n",
    "    else:\n",
    "        return df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a22e47",
   "metadata": {},
   "source": [
    "### 10. ストライド検出と抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca118961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_fz_heel_strikes(signal_array, threshold=0.05, min_dist_samples=40):\n",
    "    \"\"\"Fzの立ち上がり検出\"\"\"\n",
    "    is_contact = signal_array > threshold\n",
    "    rising_edge = np.diff(is_contact.astype(int), prepend=0) == 1\n",
    "    potential_indices = np.where(rising_edge)[0]\n",
    "    \n",
    "    if len(potential_indices) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    true_indices = [potential_indices[0]]\n",
    "    for idx in potential_indices[1:]:\n",
    "        if idx - true_indices[-1] > min_dist_samples:\n",
    "            true_indices.append(idx)\n",
    "    \n",
    "    return np.array(true_indices)\n",
    "\n",
    "def slice_strides_with_constraints(df_input, target_col, side_name=\"Left\", \n",
    "                                   threshold=0.05, fs=100, \n",
    "                                   min_duration=0.7, max_duration=1.8):\n",
    "    \"\"\"ストライド時間制約を満たす歩行のみ抽出\"\"\"\n",
    "    signal = df_input[target_col].values\n",
    "    time_array = df_input['Time (Seconds)'].values\n",
    "    \n",
    "    min_dist_samples = int(0.4 * fs)\n",
    "    hs_indices = detect_fz_heel_strikes(signal, threshold=threshold, \n",
    "                                        min_dist_samples=min_dist_samples)\n",
    "    \n",
    "    valid_strides = []\n",
    "    \n",
    "    for i in range(1, len(hs_indices) - 2):\n",
    "        start_idx = hs_indices[i]\n",
    "        end_idx = hs_indices[i+1]\n",
    "        \n",
    "        start_t = time_array[start_idx]\n",
    "        end_t = time_array[end_idx]\n",
    "        duration = end_t - start_t\n",
    "        \n",
    "        if min_duration <= duration <= max_duration:\n",
    "            stride_df = df_input.iloc[start_idx:end_idx].copy()\n",
    "            valid_strides.append(stride_df)\n",
    "    \n",
    "    print(f\"[{side_name}] Accepted Strides: {len(valid_strides)}\")\n",
    "    return valid_strides\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34776dbd",
   "metadata": {},
   "source": [
    "### 11. ストライドの正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7aff7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_strides(stride_list, target_cols, n_points=200):\n",
    "    \"\"\"各ストライドを0-100%に正規化\"\"\"\n",
    "    normalized_dfs = []\n",
    "    data_collector = []\n",
    "    \n",
    "    gait_cycle = np.linspace(0, 100, n_points)\n",
    "    x_new = np.linspace(0, 1, n_points)\n",
    "    \n",
    "    for stride_df in stride_list:\n",
    "        n_len = len(stride_df)\n",
    "        x_old = np.linspace(0, 1, n_len)\n",
    "        \n",
    "        new_df = pd.DataFrame()\n",
    "        new_df['Gait Cycle (%)'] = gait_cycle\n",
    "        \n",
    "        stride_matrix = []\n",
    "        \n",
    "        for col in target_cols:\n",
    "            if col in stride_df.columns:\n",
    "                y_old = stride_df[col].values\n",
    "                f = interp1d(x_old, y_old, kind='linear', fill_value=\"extrapolate\")\n",
    "                y_new = f(x_new)\n",
    "                new_df[col] = y_new\n",
    "                stride_matrix.append(y_new)\n",
    "            else:\n",
    "                zeros = np.zeros(n_points)\n",
    "                new_df[col] = zeros\n",
    "                stride_matrix.append(zeros)\n",
    "        \n",
    "        normalized_dfs.append(new_df)\n",
    "        data_collector.append(np.array(stride_matrix).T)\n",
    "    \n",
    "    if len(data_collector) > 0:\n",
    "        ensemble_array = np.array(data_collector)\n",
    "    else:\n",
    "        ensemble_array = np.empty((0, n_points, len(target_cols)))\n",
    "    \n",
    "    return normalized_dfs, ensemble_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf0cca9",
   "metadata": {},
   "source": [
    "### 12. 外れ値ストライドの除去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85f20ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outlier_strides(ensemble_array, stride_dfs, n_sigmas=3, \n",
    "                           outlier_ratio_threshold=0.05):\n",
    "    \"\"\"集団から大きく乖離した外れ値ストライドを除外\"\"\"\n",
    "    median_curve = np.median(ensemble_array, axis=0)\n",
    "    std_curve = np.std(ensemble_array, axis=0)\n",
    "    \n",
    "    upper_limit = median_curve + (n_sigmas * std_curve)\n",
    "    lower_limit = median_curve - (n_sigmas * std_curve)\n",
    "    \n",
    "    upper_limit_bc = upper_limit[np.newaxis, :, :]\n",
    "    lower_limit_bc = lower_limit[np.newaxis, :, :]\n",
    "    \n",
    "    is_outlier_matrix = (ensemble_array > upper_limit_bc) | (ensemble_array < lower_limit_bc)\n",
    "    \n",
    "    total_points_per_stride = ensemble_array.shape[1] * ensemble_array.shape[2]\n",
    "    outlier_counts = np.sum(is_outlier_matrix, axis=(1, 2))\n",
    "    outlier_ratios = outlier_counts / total_points_per_stride\n",
    "    \n",
    "    keep_mask = outlier_ratios <= outlier_ratio_threshold\n",
    "    \n",
    "    clean_ensemble = ensemble_array[keep_mask]\n",
    "    clean_dfs = [df for i, df in enumerate(stride_dfs) if keep_mask[i]]\n",
    "    \n",
    "    return clean_ensemble, clean_dfs, keep_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dcd1e2",
   "metadata": {},
   "source": [
    " ### 13. 左右データの統合処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c95d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_left_right_data(left_ensemble, right_ensemble, left_cols, right_cols):\n",
    "    \"\"\"\n",
    "    左右のデータを統合し，左足データを適切に反転して同じデータとして扱う\n",
    "    \n",
    "    【反転処理の詳細】\n",
    "    - 加速度: Left_Accel_X を -1倍\n",
    "    - 角速度: Left_Gyro_Y, Left_Gyro_Z を -1倍\n",
    "    - 関節角度: Left_{Joint}_ZX を -1倍（前額面の角度）\n",
    "    - 床反力: Left_Fx を -1倍\n",
    "    \n",
    "    Returns:\n",
    "        merged_ensemble: 統合された3次元配列 (左右合計ストライド数, 200, 特徴量数)\n",
    "        merged_cols: 統合されたカラム名リスト（Left_/Right_プレフィックスを削除）\n",
    "    \"\"\"\n",
    "    # 右足データはそのまま使用\n",
    "    right_data = right_ensemble.copy()\n",
    "    \n",
    "    # 左足データをコピーして反転処理\n",
    "    left_data = left_ensemble.copy()\n",
    "    \n",
    "    print(\"\\n--- 左足データの反転処理 ---\")\n",
    "    \n",
    "    # 1. 加速度X軸の反転\n",
    "    if 'Left_Accel_X' in left_cols:\n",
    "        idx = left_cols.index('Left_Accel_X')\n",
    "        left_data[:, :, idx] *= -1\n",
    "        print(f\"  ✓ Left_Accel_X を反転 (index: {idx})\")\n",
    "    \n",
    "    # 2. 角速度Y, Z軸の反転\n",
    "    for axis in ['Y', 'Z']:\n",
    "        col_name = f'Left_Gyro_{axis}'\n",
    "        if col_name in left_cols:\n",
    "            idx = left_cols.index(col_name)\n",
    "            left_data[:, :, idx] *= -1\n",
    "            print(f\"  ✓ Left_Gyro_{axis} を反転 (index: {idx})\")\n",
    "    \n",
    "    # 3. 関節角度ZX平面の反転\n",
    "    for joint in ['Hip', 'Knee', 'Ankle']:\n",
    "        col_name = f'Left_{joint}_ZX'\n",
    "        if col_name in left_cols:\n",
    "            idx = left_cols.index(col_name)\n",
    "            left_data[:, :, idx] *= -1\n",
    "            print(f\"  ✓ Left_{joint}_ZX を反転 (index: {idx})\")\n",
    "    \n",
    "    # 4. 床反力Fxの反転\n",
    "    if 'Left_Fx' in left_cols:\n",
    "        idx = left_cols.index('Left_Fx')\n",
    "        left_data[:, :, idx] *= -1\n",
    "        print(f\"  ✓ Left_Fx を反転 (index: {idx})\")\n",
    "    \n",
    "    # 左右データの結合\n",
    "    merged_ensemble = np.concatenate([left_data, right_data], axis=0)\n",
    "    \n",
    "    # カラム名は左右で共通化（Left_/Right_プレフィックスを削除）\n",
    "    # 例: Left_Accel_X, Right_Accel_X → Accel_X\n",
    "    merged_cols = [col.replace('Left_', '').replace('Right_', '') for col in left_cols]\n",
    "    \n",
    "    print(f\"\\n統合完了:\")\n",
    "    print(f\"  左足ストライド数: {left_ensemble.shape[0]}\")\n",
    "    print(f\"  右足ストライド数: {right_ensemble.shape[0]}\")\n",
    "    print(f\"  合計ストライド数: {merged_ensemble.shape[0]}\")\n",
    "    print(f\"  特徴量数: {merged_ensemble.shape[2]}\")\n",
    "    \n",
    "    return merged_ensemble, merged_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641c63e",
   "metadata": {},
   "source": [
    "### 14. メイン処理パイプライン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3571bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_participant_condition(participant, condition, mass):\n",
    "    \"\"\"1人の1条件分のデータを処理\"\"\"\n",
    "    \n",
    "    # データ読み込み\n",
    "    data = load_participant_data(participant, condition, mass)\n",
    "    \n",
    "    # 列名整理\n",
    "    df_mocap = clean_mocap_columns(data['mocap'])\n",
    "    df_force = clean_force_columns(data['force'])\n",
    "    \n",
    "    # リサンプリング\n",
    "    df_left_processed = process_resampling(data['left'], sampling_interval=10)\n",
    "    df_right_processed = process_resampling(data['right'], sampling_interval=10)\n",
    "    \n",
    "    # ローパスフィルタ\n",
    "    df_left_smoothed = process_smoothing_dataframe(df_left_processed, fs=DEVICE_FREQ)\n",
    "    df_right_smoothed = process_smoothing_dataframe(df_right_processed, fs=DEVICE_FREQ)\n",
    "    df_mocap_smoothed = process_smoothing_dataframe(df_mocap, fs=MOCAP_FREQ)\n",
    "    df_force_smoothed = process_smoothing_dataframe(df_force, fs=FORCE_FREQ)\n",
    "    \n",
    "    # 関節角度計算\n",
    "    df_angles, _, _ = process_mocap_data_target_calibration(\n",
    "        df_mocap_smoothed, df_left_smoothed)\n",
    "    \n",
    "    # 床反力の正規化\n",
    "    df_normalized = normalize_force_by_bodyweight(df_force_smoothed, mass)\n",
    "    \n",
    "    # Zスコア正規化\n",
    "    df_left_z, _ = process_hybrid_normalization(df_left_smoothed, duration=300)\n",
    "    df_right_z, _ = process_hybrid_normalization(df_right_smoothed, duration=300)\n",
    "    \n",
    "    # データ同期と結合\n",
    "    df_final = synchronize_merge_and_extract(\n",
    "        df_left_z, df_right_z, df_angles, df_normalized, target_freq=100)\n",
    "    \n",
    "    # ストライド抽出\n",
    "    left_strides = slice_strides_with_constraints(\n",
    "        df_final, 'Left_Fz', side_name=\"Left\", threshold=0.01)\n",
    "    right_strides = slice_strides_with_constraints(\n",
    "        df_final, 'Right_Fz', side_name=\"Right\", threshold=0.01)\n",
    "    \n",
    "    # カラム定義\n",
    "    cols_left = [\n",
    "        'Left_Pressure_1', 'Left_Pressure_2', 'Left_Pressure_3', 'Left_Pressure_4', \n",
    "        'Left_Pressure_5', 'Left_Pressure_6', 'Left_Pressure_7', 'Left_Pressure_8',\n",
    "        'Left_Accel_X', 'Left_Accel_Y', 'Left_Accel_Z', \n",
    "        'Left_Gyro_X', 'Left_Gyro_Y', 'Left_Gyro_Z', \n",
    "        'Left_Hip_XY', 'Left_Hip_YZ', 'Left_Hip_ZX', \n",
    "        'Left_Knee_XY', 'Left_Knee_YZ', 'Left_Knee_ZX', \n",
    "        'Left_Ankle_XY', 'Left_Ankle_YZ', 'Left_Ankle_ZX', \n",
    "        'Left_Fx', 'Left_Fy', 'Left_Fz'\n",
    "    ]\n",
    "    cols_right = [c.replace('Left', 'Right') for c in cols_left]\n",
    "    \n",
    "    # 正規化\n",
    "    left_norm_dfs, left_ensemble = normalize_strides(left_strides, cols_left, n_points=200)\n",
    "    right_norm_dfs, right_ensemble = normalize_strides(right_strides, cols_right, n_points=200)\n",
    "    \n",
    "    # 外れ値除去\n",
    "    L_ens_clean, L_dfs_clean, _ = filter_outlier_strides(\n",
    "        left_ensemble, left_norm_dfs, n_sigmas=3, outlier_ratio_threshold=0.01)\n",
    "    R_ens_clean, R_dfs_clean, _ = filter_outlier_strides(\n",
    "        right_ensemble, right_norm_dfs, n_sigmas=3, outlier_ratio_threshold=0.01)\n",
    "    \n",
    "    # 左右データの統合（反転処理を含む）\n",
    "    merged_ensemble, merged_cols = merge_left_right_data(\n",
    "        L_ens_clean, R_ens_clean, cols_left, cols_right)\n",
    "    \n",
    "    return {\n",
    "        'participant': participant,\n",
    "        'condition': condition,\n",
    "        'mass': mass,\n",
    "        'ensemble': merged_ensemble,\n",
    "        'columns': merged_cols,\n",
    "        'left_dfs': L_dfs_clean,\n",
    "        'right_dfs': R_dfs_clean\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be605c6a",
   "metadata": {},
   "source": [
    "### 15. 全実験協力者・全条件の一括処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9155d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_data():\n",
    "    \"\"\"全実験協力者・全条件のデータを処理\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    for i, participant in enumerate(PARTICIPANTS):\n",
    "        mass = MASSES[i]\n",
    "        \n",
    "        for condition in CONDITIONS:\n",
    "            try:\n",
    "                result = process_single_participant_condition(participant, condition, mass)\n",
    "                all_results.append(result)\n",
    "                \n",
    "                print(f\"\\n✓ 完了: {participant}_{condition}\")\n",
    "                print(f\"  統合ストライド数: {result['ensemble'].shape[0]}\")\n",
    "                print(f\"  特徴量数: {result['ensemble'].shape[2]}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\n✗ エラー: {participant}_{condition}\")\n",
    "                print(f\"  {str(e)}\")\n",
    "                continue\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f145ce9",
   "metadata": {},
   "source": [
    "### 16. データセットの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d50572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(all_results, output_dir='processed_data'):\n",
    "    \"\"\"処理済みデータをnpz形式で保存\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. 被験者名とIDの対応表を作成 (例: {'oba': 0, 'ono': 1, ...})\n",
    "    # all_resultsからユニークな名前を取得してソートすることでIDを固定\n",
    "    unique_participants = sorted(list(set(r['participant'] for r in all_results)))\n",
    "    participant_map = {name: i for i, name in enumerate(unique_participants)}\n",
    "    \n",
    "    print(f\"ID Map: {participant_map}\")\n",
    "\n",
    "    # 統合用リスト\n",
    "    all_ensembles = []\n",
    "    all_subject_ids = []  # ★ここに追加: IDを格納するリスト\n",
    "    \n",
    "    # 個別ファイルとして保存\n",
    "    for result in all_results:\n",
    "        filename = f\"{result['participant']}_{result['condition']}_processed.npz\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        np.savez(\n",
    "            filepath,\n",
    "            ensemble=result['ensemble'],\n",
    "            columns=result['columns'],\n",
    "            participant=result['participant'],\n",
    "            condition=result['condition'],\n",
    "            mass=result['mass']\n",
    "        )\n",
    "        print(f\"保存完了: {filepath}\")\n",
    "        \n",
    "        # 統合用データの準備\n",
    "        data = result['ensemble']\n",
    "        name = result['participant']\n",
    "        \n",
    "        # ★ここが重要: データ数と同じ長さのID配列を作成\n",
    "        # 例: データが337個でIDが0なら、[0, 0, ..., 0] (長さ337) を作る\n",
    "        n_samples = data.shape[0]\n",
    "        current_id = participant_map[name]\n",
    "        ids = np.full(n_samples, current_id)\n",
    "        \n",
    "        all_ensembles.append(data)\n",
    "        all_subject_ids.append(ids)\n",
    "    \n",
    "    # 全データを統合\n",
    "    combined_ensemble = np.concatenate(all_ensembles, axis=0) # (N, 200, 26)\n",
    "    combined_ids = np.concatenate(all_subject_ids, axis=0)    # (N, )\n",
    "    \n",
    "    # 保存\n",
    "    combined_path = os.path.join(output_dir, 'all_data_combined.npz')\n",
    "    np.savez(\n",
    "        combined_path,\n",
    "        ensemble=combined_ensemble,\n",
    "        subject_ids=combined_ids,      # ★追加: 被験者ID配列\n",
    "        columns=all_results[0]['columns'],\n",
    "        id_map=participant_map         # 参考: IDと名前の対応表も保存しておくと便利\n",
    "    )\n",
    "    \n",
    "    print(f\"\\\\n統合データ保存完了: {combined_path}\")\n",
    "    print(f\"総ストライド数 (ensemble): {combined_ensemble.shape}\")\n",
    "    print(f\"総ID数 (subject_ids): {combined_ids.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0847c39",
   "metadata": {},
   "source": [
    "### 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61a05ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: oba - Condition: H (Mass: 60.9 kg)\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# 全データ処理\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     all_results \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_all_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# データセット保存\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     save_dataset(all_results)\n",
      "Cell \u001b[0;32mIn[38], line 10\u001b[0m, in \u001b[0;36mprocess_all_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m condition \u001b[38;5;129;01min\u001b[39;00m CONDITIONS:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_single_participant_condition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticipant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmass\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         all_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ 完了: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparticipant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcondition\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[37], line 22\u001b[0m, in \u001b[0;36mprocess_single_participant_condition\u001b[0;34m(participant, condition, mass)\u001b[0m\n\u001b[1;32m     19\u001b[0m df_force_smoothed \u001b[38;5;241m=\u001b[39m process_smoothing_dataframe(df_force, fs\u001b[38;5;241m=\u001b[39mFORCE_FREQ)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 関節角度計算\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df_angles, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_mocap_data_target_calibration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_mocap_smoothed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_left_smoothed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 床反力の正規化\u001b[39;00m\n\u001b[1;32m     26\u001b[0m df_normalized \u001b[38;5;241m=\u001b[39m normalize_force_by_bodyweight(df_force_smoothed, mass)\n",
      "Cell \u001b[0;32mIn[29], line 118\u001b[0m, in \u001b[0;36mprocess_mocap_data_target_calibration\u001b[0;34m(df_target, df_ref)\u001b[0m\n\u001b[1;32m    115\u001b[0m base_pose_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(ref_angles, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# 全データの角度計算と補正\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m target_angles \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_angles_from_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m relative_angles \u001b[38;5;241m=\u001b[39m target_angles \u001b[38;5;241m-\u001b[39m base_pose_mean\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# DataFrame作成\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 79\u001b[0m, in \u001b[0;36mcalculate_angles_from_positions\u001b[0;34m(df, target_cols)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_frames):\n\u001b[1;32m     78\u001b[0m     current_pos \u001b[38;5;241m=\u001b[39m positions_3d[frame_idx]\n\u001b[0;32m---> 79\u001b[0m     angles \u001b[38;5;241m=\u001b[39m \u001b[43mcalculator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mangles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_pos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     all_angles\u001b[38;5;241m.\u001b[39mappend(angles\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(all_angles)\n",
      "Cell \u001b[0;32mIn[29], line 62\u001b[0m, in \u001b[0;36mCalculateAngle.angles\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m     53\u001b[0m idxs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     54\u001b[0m     (R_ILIUM_INDEX \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, R_GREATER_TROCHANTER_INDEX \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, R_KNEE_INDEX \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     55\u001b[0m     (L_ILIUM_INDEX \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, L_GREATER_TROCHANTER_INDEX \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, L_KNEE_INDEX \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     (L_KNEE_INDEX \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, L_MALLEOLUS_INDEX \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, L_TOE_INDEX \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     60\u001b[0m ]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (a, b, c) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(idxs):\n\u001b[0;32m---> 62\u001b[0m     out[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_angle3d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[0;32mIn[29], line 45\u001b[0m, in \u001b[0;36mCalculateAngle._angle3d\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m     43\u001b[0m     b \u001b[38;5;241m=\u001b[39m v[\u001b[38;5;241m1\u001b[39m][sl] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sl, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m v[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;28mlist\u001b[39m(sl)]\n\u001b[1;32m     44\u001b[0m     S \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (b[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m a[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m b[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m a[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 45\u001b[0m     ang \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_angle2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     deg[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m360\u001b[39m \u001b[38;5;241m-\u001b[39m ang \u001b[38;5;28;01mif\u001b[39;00m S \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m ang\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m deg\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 全データ処理\n",
    "    all_results = process_all_data()\n",
    "    \n",
    "    # データセット保存\n",
    "    save_dataset(all_results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"全処理が完了しました\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
